# scRNA_seq
A snakemake pipeline that can be used to analyze scRNA-seq data generated by 10x genomics. This pipeline can be used to analyze scRNA-seq, scVDJ-seq, and scCITE-seq. This pipeline should be cluster agnostic, but has been tested on s `slurm` cluster.

Writen by Kristen Wells

There are two main steps in running this pipeline. The first is an automated snakemake pipeline that will run `Cellranger` on your samples. The second is a set of example scripts to follow for analysis

## Snakemake pipeline

1. Download and install miniconda3: For Linux
```{bash}
wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh
```

2. Install Snakemake:
```{bash}
conda install snakemake -c bioconda -c conda-forge
```

3. Install singuarlity or docker 
This may already be installed on your system

4. Update the config file (config.yaml) - [see below for details](#config-setup)

5. Update snakecharmer.sh to your specific cluster specs. 

6. submit the job using

7. I highly recommend looking at the csv files that are generated and passed to cell ranger to ensure that the correct fastq files have been detected for each sample.


## Config setup
*Note optional means that the field in the config file can remain blank but the field must still be present*

| Parameter | Required/optional | Type | Description | Help |
|-----------|-------------------|------|-------------|------|
| SCRATCH_DIR | optional | string | Path to scratch space | A path to a directory that can be used for temporary files. This is not a true temporary directory, as these files will be needed for the rest of the pipeline, but are not needed permanantely. If you want to save space and put these large files in a different place than the main directory, put that path here. The full path to your results will be fully recreated. If you don't want to use this option, leave it blank and all results will be placed within the results directory. | 
| BASE_PATH | optional | string | Path to base dir | A path to the base directory. Setting this makes it so only a relative path from the base path is added to your scratch directory. Leaving this empty just puts the full current path into your scratch space. |
| RAW_DATA | required | string/list | Location of the raw data | Where the raw data is located. Multiple directories can be given if samples were sequenced multiple times |
| SAMPLES | required | list | list of sample names | the list of samples you want to test. This is the name that will be in the output files. The order must be identical to the order of RNA_SAMPLES, ADT_SAMPLES, and VDJ_SAMPLES |
| AGGR_SAMPLES | optional | list | samples to aggregate | Which samples should be aggregated together at the end of the pipeline. These should be samples that were split between multiple 10x runs. I generally do not recommend setting this option as it downsamples all reads to the lowest sample. Instead I prefer to merge the full samples and batch correct with `harmony` or `mnn` |
| RNA_SAMPLES | required | list | RNA sample names | The name of the RNA samples. Not the full fastq name, but the name that is the same for all samples. Likely ends in "GEX" |
| ADT_SAMPLES | optional | list | ADT sample names | The name of the samples from CITE-seq or hashtagging. If CITE-seq and hashtagging files are separate, include them both separated by a comma. Put samples in the same order as their RNA counterparts. If CITE-seq or hashtagging were not performed, leave this blank. |
| VDJ_T_SAMPLES | optional | list | VDJ T sample names | The name of the samples from TCR VDJ-seq. Put samples in the same order as their RNA counterparts. If TCR VDJ-sequencing was not peformed, leave this blank. |
| VDJ_B_SAMPLES | optional | list | VDJ B sample names | The name of the samples from BCR VDJ-seq. Put samples in the same order as their RNA counterparts. If BCR VDJ-sequencing was not peformed, leave this blank. |
| RESULTS | required | string | Path to the output directory | Path to the output directory. This directory will be made and all final results will be placed here |
| GENOME | required | string | Path to the cellranger genome reference | You can download these references from 10x genomics or make them with `mkref`. |
| ADT_REF | optional | string | Path to the ADT-reference. | This should be a comma separated file with the columns described in the 10x tutorial: id, name, read, pattern, sequence, and feature_type. The feature_type will be Antibody Capture. The name will be the name in the final output matrix. Leave this blank if CITE-seq or hashtagging were not performed. |
| VDJ_REF | optional | string | Path to the cellranger VDJ reference. | You can download this reference from 10x genmoics. If VDJ sequencing were not performed, leave this blank. |
| MAX_JOBS | required | integer | cellranger jobs | The maximum number of jobs that can be submitted by cell ranger at a time |
| CLUSTER_TEMPLATE | optional | string | path to a template | This is the template needed from 10x genomics to submit jobs on a cluster. You can download templates on their website. One is included in this git repo. If you don't want cellranger to submit jobs, leave this blank (which will set cellranger on the local jobmode) |
| CHEMISTRY | optional | list | 10x chemistry | Arguments to the `--chemstiry` flag in cellranger count. If left blank, chemistry will be `auto`. Only use this if the pipeline failed because of a failure to detect the chemistry. Can be filled in for only some samples. |
| VELOCITO_GROUP | optional | list | what samples to combine prior to running RNA velocity | Leave this blank unless you want to run RNA velocity on many samples combined.
| **R script options** |
| SCRIPT_PATH | required | string | Path to the scripts | This is the path to where the scripts are located. If you downloaded this repo, it would be `src/scripts` |
| SCRIPTS_RUN | optional | list | Scripts to run | Any scripts put here will be run as is in order and will not be run in parallel. |
| SAMPLE_SCRIPTS | optional | dictionary | Samples and scripts | Any scripts that you want to run on all samples should go here. You should include the samples you want to run through these scripts under "samples". If you want to run all samples, just put "all" under "samples". Under "scripts_run" include the name of the scripts that you want to run. Each of these will be run on every sample in order. All samples will be processed in parallel. These scripts should be located under `{SCRIPT_PATH}/individual_analysis`. Note, information about all of these samples should be filled in in the `SAMPLE_INFO` file. |
| MERGE_SCRIPTS | optional | dictionary | Merged samples and scripts. | Any samples that you want to merge should go here. The name of the merged sample should go under "samples". Include the samples that should be merged in the sample sheet under "merge_samples". If you want to instead merge all samples, include "all" under "samples". You can include a list of merged samples, so feel free to do as many differet types of merging as you want. As with the individual, all samples will be processed in parallel. All scripts you want run should go under "scripts_run". These scripts should be located under `{SCRIPT_PATH}/integrated_analysis`.  Note, information about all of these samples should also be filled in in the `SAMPLE_INFO` file. These scripts will be run after any of the individual scripts of the samples included in the "merge_samples" |
| SUBSET_SCRIPTS | optional | dictionary | Subsetted samples and scripts. | Any samples that you want to subset should go here. Note, you must include a script in the `MERGE_SCRIPTS` that performs the subsetting, variable gene finding, and data scaling as the subsetting will run the same scripts as the merge, but will skip the first. The name of the subset sample should go under "samples". Include the samples that should be subsetted in the sample sheet under "subset_from". You can include a list of subsetted samples, so feel free to do as many differet types of subsetting as you want. As with the individual, all samples will be processed in parallel. All scripts you want run should go under "scripts_run". These scripts should be located under `{SCRIPT_PATH}/integrated_analysis`.  Note, information about all of these samples should also be filled in in the `SAMPLE_INFO` file. These scripts will be run after any of the merged scripts of the merged samples included in the "subset_from" |
| SAMPLE_INFO | required | string | Path to the sample info | This file contains all the sample info for every sample. It should have the following columns. `sample`, `HTO`, `ADT`, `hash_ident`, `VDJ_T`, `VDJ_B`, `adt_pca`, `adt_umap`, `PCs`, `resolution`, `merge_samples`, `subset_from`, `batch_correction`. These are described in the [sample info section](#sample-info) |
| RSCRIPT_CONTAINER | optional | string | path to R script container | Only needed if running within the singularity or docker image. It can be downloaded [here](https://hub.docker.com/repository/docker/kwellswrasman/smith_2024_r_docker/general) or built from the `docker/r_docker` recipe |
| DROPKICK_CONTAINER | optional | string | path to R script container | Only needed if running within the singularity or docker image. The can be downloaded [here](https://hub.docker.com/repository/docker/kwellswrasman/dropkick/general) or built from the `docker/dropkick` recipe |
| SCAR_CONTAINER | optional | string | path to R script container | Only needed if running within the singularity or docker image. The can be downloaded [here](https://hub.docker.com/repository/docker/kwellswrasman/scar/generall) or built from the `docker/r_docker` recipe |
| IMMCANTATION_CONTAINER | optional | string | path to immcantation container | Only needed if running within the singularity or docker image. The can be downloaded following instructions [here](https://immcantation.readthedocs.io/en/stable/docker/intro.html) |


## Sample info
| Column | Type  | Description | Help |
|--------|-------|-------------|------|
| `sample`| string | name of the sample | if this is for the individual analysis, the sample names should match those under `SAMPLES` in the config file. They should also match the names under `samples` in `SAMPLE_SCRIPTS`. If this is for merged, they should match the name under `samples` in `MERGED_SCRIPTS` or for subsetted, they should match the name under `samples` in `SUBSET_SCRIPTS`. Right now, you have to manually update the subset script to correctly name the new subsetted object and this must then match the name under `samples` in `SUBSET_SCRIPTS`. |
| `HTO` | boolean | Are HTOs included | Set to TRUE if HTOs are included in your dataset, FALSE if not. This just makes it so your object is made correctly and will run demultiplexing on HTOs if they are included. |
| `ADT` | boolean | Are ADTs included | Set to TRUE if ADTs are included, FALSE if they are not. This will make an ADT assay in your Seurat object if they are included and will include them in your plots. |
| `hash_ident` | string | pattern to find the htos | Provide a pattern to identify the HTOs from the ADT assay if they are there. This is just used to split the HTO and ADT into separate assays. |
| `VDJ_T` | boolean | Are VDJ TCRs included | Set to TRUE if VDJ on TCR was run. If so, TCR data will be loaded into the Seurat object. |
| `VDJ_B` | boolean | Are VDJ BCRs included | Set to TRUE if VDJ on TCR was run. If so, BCR data will be loaded into the Seurat object. |
| `adt_pca` | boolean | Should PCA be run on ADTs | Only set this to TRUE if you have more than 30 ADTs and ADTs were run, otherwise set to FALSE. |
| `adt_umap` | boolean | Should UMAP be run on ADTs | Only set this to TRUE if you have ADTs and want to also make a UMAP using ADTs and combined ADT and RNA. Otherwise set to FALSE |
| `PCs` | integer | Number of PCs | The number of PCs to use for clustering and UMAP dimensionality reduction. Images in `results/R_analysis/{sample}/images/RNA_pca.pdf` will be helpful to identify the number of PCs to use. |
| `resolution` | integer | clustering resolution | The clustering resolution to use. Many will be tested and plotted for you. Images in `results/R_analysis/{sample}/images/clustering_resolution.pdf` will be helpful to identify the number of PCs to use. |
| `merge_samples` | comma separated values | What samples to merge | If this is a merged sample, include a comma separated list of samples to merge. The processed rda files from these will be read in and merged. If this isn't a merged sample, set to `NA` |
|  `subset_from` | comma separated values | What samples to subset | If this is a subsetted sample, include the value of the merged sample it was subset from. This is primarily used to ensure all appropriate scripts are run before running this one. If this isn't a subsetted sample, set to `NA` |
| `batch_correction` | string | batch correction to use | What batch correction to use on a merged sample, set to `rna` (no correction), `mnn` (mutual nearest neighbor) or `harmony` (harmony). If this isn't a merged sample, set to `NA`. |

## Output files
If you run all scripts in the repo, the following files will be made. All output files will be in `{results}/R_analysis/{sample}` where the `results` is the same as the `RESULTS_DIR` in the config and the `sample` is the same as the sample in `sample_info`. Each of these directories has `images` (where all images are saved), `rda_obj` (where all rda objects are saved), and `files` (where all files are saved).

| File name | Type | Description |
|-----------|------|-------------|
| **rda_obj** |
| `rda_obj/seurat_unfilt.rds` | R object | The fully unprocesed seurat object, this will contain all cells output by cellranger |
| `rda_obj/seurat_start.rds` | R object | The Seurat object where all low quality cells have been removed |
| `rda_obj/seurat_doublet.rds` | R object | The Seurat object where doublets have been labed but not removed |
| `rda_obj/seurat_processed.rds` | R object | The fully processed Seurat object. If the full pipeline has been run, this will include dimensionality reductions, clustering, and cell type identificaiton |
| **images** |
| `images/RNA_pca.pdf` | pdf file | Images associated with running the PCA. This includes genes associate with top PCs, PC 1 and 2 plotted and colored by QC metrics, jackstraw, and elbow plot. These are helpful for determining data quality and number of PCs for downstream analysis. |
| `images/clustering_resolution.pdf` | pdf file | Images associated with clustering. Many clustering resolutions are run. This is a comparision of those different resoultions (showing how cells move between them) and all resolutions plotted on the UMAP. This is helpful for determining downstream resolutions |
| `images/celltype_mapping.pdf` | pdf file | Images created when mapping the sample to referenes. This includes a heatmap showing correlation between your clusters and the reference and UMAPs colored by this new cell type identification. If many references are included, this will also include a UMAP based on the top hit from any reference. |
| `images/testing_batch_correction.pdf`| pdf file | Only present if merging was done. This shows UMAPs of no correction, `mnn` correction, and `harmony` correction colored by cluster, celltype, and sample as well as a heatmap comparing the similarity of clusters identified after `mnn` and `harmony` batch correction. |


## R scripts

All of these r scripts are currently written to run within the snakemake pipeline, however you are welcome to run and modify them on your own.

R scripts for the analysis are found in `src/scripts`. There are two directories here. One called `individual_analysis` includes scripts to process an individual sample. `intigrated_analysis` contains scripts to run analysis on multiple samples.

To run these scripts outside of the docker container, you will need to install my custom analysis package `scAnalysisR`:

```R
install.packages("devtools")
library(devtools)
install_github("CUAnschutzBDC/scAnalysisR")
```

Scripts within each directory are numbered based on the order in which they should be run.

They include:

1. Steps for intial processing and filtering of the data
2. Steps for doublet removal
3. Steps for normalizing ADTs (if they are present in your data)
4. Steps for dimensional reduction with PCA and UMAP either on RNA alone or with ADTs included
5. Steps to name clusters based on references with `clustifyr`
6. Steps for marker detection
7. Steps for gene ontology and pathway analysis
8. Steps for integrating multiple samples
9. Steps for differential expression when multiple samples are present

For many of these steps, I've included different methods of performing them (for example batch correction can be done with `harmony` or `fastMNN`) and ways of comparing the different approaches so you can make an informed decision about what method is best for your samples.

For all scripts in this analysis, please make sure you understand the processing steps so you know what are the appropriate parameters for each step. These scripts are not intended to be run blindly with no understanding of the underlying algorithims.
